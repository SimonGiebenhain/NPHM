<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Learning Neural Parametric Head Models">
    <meta name="keywords" content="NPHM, Neural Fields, Virtual Avatars, Signed Distance Field, Deformation Field, 3D Scanning, Dataset">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Learning Neural Parametric Head Models</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-E0HR9YQK2K"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-E0HR9YQK2K');
    </script>



    <!-- Global site tag (gtag.js) - Google Analytics -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <style>
		.render_wrapper {
			position: relative;
            height: 300px;
         }
        .render_wrapper_small {
			position: relative;
            height: 200px;
         }
		.render_div {
			position: absolute;
			top: 0;
			left: 0;
		}

        #interpolation-image-wrapper-car{
            text-align: center;
        }
        #interpolation-image-wrapper-chair{
            text-align: center;
        }
        .nested-columns {
            margin-bottom: 0 !important;
        }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Learning Neural Parametric Head Models</h1>
			 <h2 class="is-size-3">CVPR 2023</h2>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://simongiebenhain.github.io">Simon Giebenhain</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://niessnerlab.org/members/tobias_kirschstein/profile.html">Tobias Kirschstein</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="todo">Markos Georgopoulos</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.martinruenz.de/">Martin Rünz</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="">Lourdes Agapito</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias
                                    Nießner</a><sup>1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Technical University of Munich,</span>
                            <span class="author-block"><sup>2</sup>Synthesia</span>
                            <span class="author-block"><sup>3</sup>University College London</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="static/NPHM.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark" href="https://arxiv.org/pdf/2212.02761.pdf">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="https://www.youtube.com/watch?v=0mDk2tFOJCg"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <svg class="svg-inline--fa fa-youtube fa-w-18" aria-hidden="true"
                                                focusable="false" data-prefix="fab" data-icon="youtube" role="img"
                                                xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"
                                                data-fa-i2svg="">
                                                <path fill="currentColor"
                                                    d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z">
                                                </path>
                                            </svg><!-- <i class="fab fa-youtube"></i> Font Awesome fontawesome.com -->
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>


                                <!-- Github Link. -->
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark" href="https://github.com/SimonGiebenhain/NPHM#learning-neural-parametric-head-models-nphm">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark" href="https://forms.gle/66xWfAxzCvsoqcNZ8">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block"></span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="./static/teaser/teaser.jpg" height="150%" />
                <h2 class=" subtitle has-text-centered" style="padding-top: 10px">
                    <p align="left">
                    We propose to learn a neural parametric head model based on neural fields: first, we capture a large dataset of over 2000 high-fidelity head scans with varying shapes and expressions (left).
                    We then non-rigidly register these scans to generate our training data.
                    As a result of training, we obtain a disentangled latent that spans the space of shapes $\mathbf{z}_{id}$ and expressions $\mathbf{z}_{ex}$ (middle).
                    At inference time, we can leverage the prior of our learned representation by fitting our model to a sparse input point cloud by solving for the latent codes (right).
                    </p>
                </h2>
            </div>
        </div>
    </section>


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_1" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_3" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_2" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_1" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_3" class="render_div"></div>
                    </div>
                </div>
                <div style="text-align: center;">Press <b>R</b> to reset views. </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p margin="0">
                        We propose a novel 3D morphable model (3DMM) for complete human heads based on hybrid neural fields. <br>
                        At the core of our model lies a neural parametric representation which disentangles identity and expressions in a disjoint latent space.
                        To this end, we capture a person's identity in a canonical space as a signed distance field (SDF) and model facial expressions with a neural deformation field.
                        <br>
                        In addition, our representation achieves high-fidelity local detail by introducing an ensemble of local fields centered around facial anchor points.
                        <br>
                        To facilitate generalization, we train our model on a newly-captured dataset of over 2000 face scans from 120 different identities using a custom high-end 3D scanning set-up. Our dataset significantly exceeds comparable existing datasets, both with respect to quality and completeness of geometry, averaging around 3.5M faces per scan.
                        <br>
                        Finally, we demonstrate that our approach outperforms state-of-the-art methods by a significant margin in terms of fitting error and reconstruction quality.
                    </div>
                </div>
            </div>

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/0mDk2tFOJCg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
            <!--/ Paper video. -->
        </div>
    </section>




    <section class="section">
        <div class="container is-max-desktop">

            <!--
            <h3 class="title is-4">Latent Interpolation</h3>
            <div class="content has-text-justified">
                <p>
                    Our learned, disentangled representation allows for smooth latent interpolation of identity (left) and expression (right), respecitvely.
                </p>
            </div>
            <div class="columns is-vcentered" style="margin-top: 10px">
                <div class="column columns nested-columns is-vcentered interpolation-panel">
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/chair/000.jpg"
                             class="interpolation-image"
                             alt="Interpolate start reference image."/>
                        <p>Start Frame</p>
                    </div>
                    <div class="column interpolation-video-column">
                        <div id="interpolation-image-wrapper-chair">
                          Loading...
                        </div>
                        <input class="slider is-fullwidth is-large is-info"
                               id="interpolation-slider-chair"
                               step="1" min="0" max="20" value="0" type="range">
                    </div>
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/chair/020.jpg"
                             class="interpolation-image"
                             alt="Interpolation end reference image."/>
                        <p class="is-bold">End Frame</p>
                    </div>
                </div>

                <div class="column columns nested-columns is-vcentered interpolation-panel" style="margin-left: 20px">
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/car/000.jpg"
                             class="interpolation-image"
                             alt="Interpolate start reference image."/>
                        <p>Start Frame</p>
                    </div>
                    <div class="column interpolation-video-column">
                        <div id="interpolation-image-wrapper-car">
                          Loading...
                        </div>
                        <input class="slider is-fullwidth is-large is-info"
                               id="interpolation-slider-car"
                               step="1" min="0" max="17" value="0" type="range">
                    </div>
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/car/017.jpg"
                             class="interpolation-image"
                             alt="Interpolation end reference image."/>
                        <p class="is-bold">End Frame</p>
                    </div>
                </div>
            </div>
            -->
            <div class="container is-max-desktop">
        <div class="content has-text-justified">
            <h2 class="title is-4">Latent Shape Interpolation</h2>
              <p>
                Here is an interactive viewer allowing to interpolate between for identities. Drag the
                <span style="color: #29e">blue cursor</span> around to change latent identity description $\mathbf{z}_{\text{id}}$
                  and observe the reulting change of geometry on the right.
              </p>
        </div>
        <div class="columns is-centered">
          <div class="column is-half">
            <div class="hyper-space-wrapper-shape has-text-centered">
              <div class="hyper-space-axis-shape">
                <div class="hyper-space-shape-outer">
                    <div class="hyper-space-shape">
                        <div class="hyper-space-cursor-shape"></div>
                  </div>
                </div>
              </div>
              Latent Shape Coordinates
              <br/>
              <small>(Quadrilateral linear interpolation between 4 cornering identites.)</small>
            </div>
          </div>
          <div class="column is-half has-text-centered">
            <div class="hyper-grid-wrapper-shape">
              <div class="hyper-grid-rgb-shape">
                <img src="./static/figures/hyper_grid_shape.jpg"/>
              </div>
            </div>
            Resulting geometry in canonical expression.
          </div>
        </div>
      </div>

            <div class="container is-max-desktop">
        <div class="content has-text-justified">
            <br>
            <h2 class="title is-4">Latent Expression Interpolation</h2>
              <p>
                Here is an interactive viewer allowing for interpolations between four different expressions. Drag the
                <span style="color: #29e">blue cursor</span> around to change $\mathbf{z}_{\text{ex}}$, which deforms a fixed identity on the right.
              </p>
        </div>


        <div class="columns is-centered">
          <div class="column is-half">
            <div class="hyper-space-wrapper has-text-centered">
              <div class="hyper-space-axis">
                <div class="hyper-space-outer">
                  <div class="hyper-space">
                    <div class="hyper-space-cursor"></div>
                  </div>
                </div>
              </div>
              Latent Expression Coordinates
              <br/>
              <small>(Quadrilateral linear interpolation between 4 cornering expressions.)</small>
            </div>
          </div>
          <div class="column is-half has-text-centered">
            <div class="hyper-grid-wrapper">
              <div class="hyper-grid-rgb">
                <img src="./static/figures/hyper_grid_sq.jpg"/>
              </div>
            </div>
            Deformed Neutral Mesh
          </div>
        </div>
      </div>





            <!-- Expression Transfer. -->
            <div class="columns is-centered" style="margin-top: 25px">
                <div class="column is-full-width">
                    <h2 class="title is-4">Expression Transfer</h2>
                    <div class="content has-text-justified">
                        <p>
                            Futhermore, the disentangled structure of NPHM allows us to transfer expressions from one subject to others.
                            <br>
                            Here we show one subject acting as actor and apply its expressions $\mathbf{z}_{ex}$ to 3 other test set subjects.
                            <br>
                            The neutral expression shows each subject in their repsecive neutral expression.
                        </p>
                    </div>
                    <div class="columns is-centered">
                        <div class="column is-2">
                            <div class="buttons is-centered" style="height: 10%">
                              <button class="button" id="style_button_0" style="background-color: #0a0a0a; color: #d5d5d5; height:35px; width: 100%">Neutral</button>
                              <button class="button" id="style_button_2" style="background-color: #c27ba0ff; color: #0a0a0a; height:35px; width: 100%">Expression 1</button>
                              <button class="button" id="style_button_3" style="background-color: #c27ba0ff; color: #0a0a0a; height:35px; width: 100%">Expression 2</button>
                              <button class="button" id="style_button_4" style="background-color: #c27ba0ff; color: #0a0a0a; height:35px; width: 100%">Expression 3</button>
                              <button class="button" id="style_button_5" style="background-color: #c27ba0ff; color: #0a0a0a; height:35px; width: 100%">Expression 4</button>
                            </div>
                        </div>
                        <div class="column" style="background-color: #f3cc66ff; margin-left: -5px;text-align: center;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_0" class="render_div"></div>
                            </div>
                            Source/Actor
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px;text-align: center;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_1" class="render_div"></div>
                            </div>
                            Target 1
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px; text-align: center;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_2" class="render_div"></div>
                            </div>
                            Target 2
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px; text-align: center;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_3" class="render_div"></div>
                            </div>
                            Target 3
                        </div>
                    </div>

                    <div class="content" style="text-align: center">
                        [Select expressions on the left. Press <b>R</b> to reset view. ]
                    </div>
                </div>
            </div>
            <!--/ Animation. -->

            <!-- Overview. -->
            <div class="columns is-centered" style="margin-top: 15px">
                <div class="column is-full-width">
                    <h2 class="title is-4">Method Overview</h2>
                    <img src="./static/teaser/overview.jpg"/>
                    <div class="content has-text-justified" style="padding-top: 15px">
                        <p><b>1.</b> We capture a dataset of 124 identities in 20 different expressions. The neutral expression has an open mouth to avoid topological issues.</p>
                        <p><b>2.</b> We directly train our identity network on the raw neutral scans.</p>
                        <p><b>3.</b> Building on 2D facial landmark detectors, we non-rigidly register a common template against all scans.</p>
                        <p><b>4.</b> We estimate the ground truth deformation fields between expression using the registrations and directly supervise our expression network.</p>
                        <p><b>5.</b> Our identity network represents shapes implicitly using an ensemble of local MLPs, each described by an individual latent vector.
                            We incorporate a symmetry prior by mirroring the local coordinate systems of symmetric MLPs and share their parameters.</p>
                    </div>

                </div>
            </div>

            <div class="columns is-centered" style="margin-top: 15px">
                <div class="column is-full-width">
                    <h2 class="title is-4">Dataset</h2>
                        <p align="left">
                        The animation below displays 4 identities from our dataset, performing all 20 expressions.
                        In total our dataset contains 124 identities and more than 2200 scans in total.
                        <br>
                        Our scans capture a high level of detail and are very complete, including good capture of hair.
                        On average, each mesh has 3.5M faces. (Note that we added 3 additional expressions for our latest 50 scanning subjects.)
                        </p>
                    <img src="./static/dataset/animated.gif" height="250%" />


                </div>
            </div>

            <!--
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method Overview</h2>
                </div>
            </div>
            <section class="hero teaser">
                <div class="container is-max-desktop">
                    <div class="hero-body">
                        <img src="./static/teaser/overview.jpg"/>
                    </div>
                </div>
            </section>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="content has-text-justified">
                        <p>Surface features from an input 3D mesh are encoded through a face convolution-based encoder and decoded through a StyleGAN2-inspired decoder to generate textures directly on the surface of the mesh.</p>
                        <p>To ensure that generated textures are realistic, the textured mesh is differentiably rendered from different view points and is critiqued by two discriminators.</p>
                        <p>An image discriminator D<sub>I</sub> operates on full image views from the real or rendered views, while a patch-consistency discriminator D<sub>P</sub> encourages consistency between views by operating on patches coming from a single real view or patches from different views of rendered images.</p>
                    </div>
                </div>
            </div>
            -->

            <!-- Concurrent Work. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Related Links</h2>

                    <div class="content has-text-justified">
                        <p>
                            For more work on similar tasks, please check out the following papers.
                        </p>
                        <p>
                            <a href="https://pablopalafox.github.io/npms/">NPMs</a> learns a parametric model for human bodies,
                            and <a href="https://pablopalafox.github.io/spams/">SPAMs</a> extends the idea to a part based representation (torso, legs, arms, head).
                        </p>

                        <p>
                            <a href="https://vcai.mpi-inf.mpg.de/projects/i3DMM/"> i3DMMs</a> and <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.pdf"> ImFace</a> both learn a neural-field-based 3DMM
                            without requiring non-rigid registration.
                        </p>

                        <p>
                            <a href="https://pengsongyou.github.io/conv_onet"> Convolutionl Occupancy Networks</a> explore regular (2D planes and 3D grids) local conditioning for implicit shape representation.
                            <a href="https://github.com/SimonGiebenhain/AIR-Nets"> AIR-Net</a> explores attention operators for locally conditioned implicit representations, which allows for less regular structure.
                            <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Genova_Local_Deep_Implicit_Functions_for_3D_Shape_CVPR_2020_paper.pdf"> Local Deep Implicit Funcions</a> also a use a flexible, point-based conditioning with Gaussian influence.

                        </p>
                    </div>
                </div>
            </div>
            <!--/ Concurrent Work. -->

        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre>
<code>
@inproceedings{giebenhain2023nphm,
 author={Simon Giebenhain and Tobias Kirschstein and Markos Georgopoulos and  Martin R{\"{u}}nz and Lourdes Agapito and Matthias Nie{\ss}ner},
 title={Learning Neural Parametric Head Models},
 booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
 year = {2023}}
</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="static/nphm.pdf">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/SimonGiebenhain" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p style="text-align:center">
                            Source code mainly borrowed from <a href="https://keunhong.com/">Keunhong Park</a>'s
                            <a href="https://nerfies.github.io/">Nerfies website</a> and
                            <a href="https://niessnerlab.org/members/yawar_siddiqui/profile.html">Yawar Siddiqui's</a> adoption for
                            <a href="https://nihalsid.github.io/texturify//">Texturify</a>.
                        </p>
                        <p style="text-align:center">
                            Please contact <a href="https://niessnerlab.org/members/simon_giebenhain/profile.html">Simon Giebenhain</a> for feedback and questions.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>





    <!-- Import maps polyfill -->
    <!-- Remove this when import maps will be widely supported -->
    <script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>

    <script type="importmap">
        {
            "imports": {
                "three": "./js/three.module.js"
            }
        }
    </script>

    <script type="module">

        import * as THREE from 'three';

        import { PLYLoader } from './js/PLYLoader.js';
        import { OrbitControls } from './js/OrbitControls.js'
        let div_to_scene = {
            "mesh_chair_0": {
                "geo": null,
            },
            "mesh_chair_1": {
                "geo": null,
            },
            "mesh_chair_2": {
                "geo": null,
            },
            "mesh_chair_3": {
                "geo": null,
            },
            "mesh_car_0": {
                "geo": null,
            },
            "mesh_car_1": {
                "geo": null,
            },
            "mesh_car_2": {
                "geo": null,
            },
            "mesh_car_3": {
                "geo": null,
            }
        }
        let div_to_render_scene = {
            "mesh_style_0": {
                "0": null,
                "2": null,
                "3": null,
                "4": null,
                "5": null,
            },
            "mesh_style_1": {
                "0": null,
                "2": null,
                "3": null,
                "4": null,
                "5": null,
            },
            "mesh_style_2": {
                "0": null,
                "2": null,
                "3": null,
                "4": null,
                "5": null,

            },
            "mesh_style_3": {
                "0": null,
                "2": null,
                "3": null,
                "4": null,
                "5": null,
            },
        }
        let mouse_button_down = false;
        let list_of_orbit_controls = []
        let style_camera = null;
        let render_colors = true;
        let style_id = "0"

        function setup_camera(div_name){
            let container = document.getElementById(div_name);
            let width = container.parentElement.clientWidth;
            let height = container.parentElement.clientHeight;
            console.log(width, height)
            let camera = new THREE.PerspectiveCamera( 35, width / height, 0.1, 50 );
            //let camera_init_position = new THREE.Vector3( -1.5, 0.35, 1.2 );
            let camera_init_position = new THREE.Vector3( 0., 0., 1.2 );
            camera_init_position = camera_init_position.multiplyScalar(1.5)
            //if (div_name.includes("style")) {
            //    camera_init_position = camera_init_position.multiplyScalar(1.25)
            //}
            //else if (div_name.includes("style")) {
            //    camera_init_position = camera_init_position.multiplyScalar(1.25)
            //}
            camera.position.set(camera_init_position.x, camera_init_position.y, camera_init_position.z);
            return camera;
        }

        function setup_render_divs(div_name, mesh_path){
            let camera = setup_camera(div_name)
            let orbit_control = create_render_div(camera, div_name, mesh_path)
            list_of_orbit_controls.push(orbit_control)
        }

        function setup_style_render_divs(div_name, mesh_path){
            if (style_camera == null) {
                style_camera = setup_camera(div_name)
            }
            let orbit_control = create_style_render_div(style_camera, div_name, mesh_path, true)
            list_of_orbit_controls.push(orbit_control)
            document.getElementById("style_button_0").addEventListener("click", set_style_0)
            document.getElementById("style_button_2").addEventListener("click", set_style_2)
            document.getElementById("style_button_3").addEventListener("click", set_style_3)
            document.getElementById("style_button_4").addEventListener("click", set_style_4)
            document.getElementById("style_button_5").addEventListener("click", set_style_5)
        }

        function create_render_div(camera, div_id, mesh_path) {
            let container;
            let renderer, controls;

            init();
            animate();

            function init() {

                container = document.getElementById(div_id);
                let width = container.parentElement.clientWidth;
                let height = container.parentElement.clientHeight;


                div_to_scene[div_id]["geo"] = new THREE.Scene();
                div_to_scene[div_id]["geo"].background = new THREE.Color( 0xffffff );
                //var axesHelper = new THREE.AxesHelper( 5 );
                //div_to_scene[div_id]["geo"].add( axesHelper );

                // PLY file

                const loader = new PLYLoader();
                loader.load( mesh_path, function ( geometry ) {

                    geometry.computeVertexNormals();
                    //let material_geo = new THREE.MeshStandardMaterial( { color: 0x444444, flatShading: true, roughness: 0.5, metalness: 0.3 } )
                    //let material_geo = new THREE.MeshPhongMaterial( { color: 0x999999, depthWrite: false} )
                    const material_geo = new THREE.MeshPhongMaterial( {
                                                color: 0xCCE6FF,
                                                specular: 0x222222,
                                                shininess: 25,} );

                    const mesh_geo = new THREE.Mesh( geometry, material_geo );
                    //mesh_geo.castShadow = true;
				    //mesh_geo.receiveShadow = true;
                    div_to_scene[div_id]["geo"].add( mesh_geo );

                }, (xhr) => {
                    console.log((xhr.loaded / xhr.total) * 100 + '% loaded')
                }, (error) => {
                    console.log(error)
                }
                );

                // lights

                //div_to_scene[div_id]["geo"].add( new THREE.HemisphereLight( 0x333333, 0x222222) );
                //div_to_scene[div_id]["geo"].add(new THREE.AmbientLight( 0x333333, 1) );
                //const directionalLight = new THREE.DirectionalLight( 0xffffff, 1. );
                //directionalLight.position.set( 1, 1, 1 );
                //div_to_scene[div_id]["geo"].add( directionalLight );
                //addShadowedLight(div_to_scene[div_id]["geo"], -5, -5, 5, 0xffffff, 1. );
                //addShadowedLight(div_to_scene[div_id]["geo"], 1, 1, 1, 0xffffff, 1.35 );
                //addShadowedLight(div_to_scene[div_id]["geo"], -1, 1, -1, 0xffffff, 1.35 );
                //addShadowedLight(div_to_scene[div_id]["geo"], 0, -2, 1, 0xffffff, 0.5 );
                //addShadowedLight(div_to_scene[div_id]["geo"],  0, -1, 2, 0xffffff, 0.5 );

                add_lights(div_to_scene[div_id]["geo"])




                // renderer

                renderer = new THREE.WebGLRenderer( { antialias: true } );
                renderer.setPixelRatio( window.devicePixelRatio );
                renderer.setSize( width, height);
                renderer.outputEncoding = THREE.sRGBEncoding;

                //renderer.shadowMap.enabled = true;

                container.appendChild( renderer.domElement );

                controls = new OrbitControls(camera, renderer.domElement)
                controls.enableDamping = false
                controls.autoRotate = true


                // resize

                window.addEventListener( 'resize', onWindowResize );
                //controls.addEventListener('change', onChange)
                controls.addEventListener('start', function(){
                  //clearTimeout(autorotateTimeout);
                  controls.autoRotate = false;
                });

                // restart autorotate after the last interaction & an idle time has passed
                //this.controls.addEventListener('end', function(){
                //  autorotateTimeout = setTimeout(function(){
                //    controls.autoRotate = true;
                //  }, 1000);
                //});

        }
            function onWindowResize() {
                let width = container.clientWidth;
                let height = container.clientHeight;
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize( width, height );
            }
            function animate() {
                requestAnimationFrame( animate );
                controls.update();
                render();
            }

            function render() {
                renderer.render( div_to_scene[div_id]["geo"], camera );
                controls.update();
            }

            return controls;
        }

        function add_lights(scene) {
                scene.add( new THREE.HemisphereLight( 0x443333, 0x111122 ,0.05) );
				const spotLight = new THREE.SpotLight( 0xffffff, 0.5 );
				spotLight.position.set( 0.0, 0.5, 1 );
				const spotLight2 = new THREE.SpotLight( 0xffffff, 0.25 );
			    spotLight2.position.set( -2, 0.3, -0.2 );
				const spotLight3 = new THREE.SpotLight( 0xffffff, 0.25 );
				spotLight3.position.set( 2, -0.3, 0.2 );
				const spotLight4 = new THREE.SpotLight( 0xffffff, 0.25 );
				spotLight4.position.set( 0.0, 1, -2 );
				const spotLight5 = new THREE.SpotLight( 0xffffff, 0.05 );
				spotLight5.position.set( 0, -2.5, -1 );
				////spotLight.position.multiplyScalar( 700 );
				scene.add( spotLight );
				scene.add( spotLight2 );
				scene.add( spotLight3 );
				scene.add( spotLight4 );
				scene.add( spotLight5 );


        }

        function add_lightsBACKUP(scene) {
                scene.add( new THREE.HemisphereLight( 0x443333, 0x111122 ,0.05) );
				const spotLight = new THREE.SpotLight( 0xffffff, 0.6 );
				spotLight.position.set( 0.5, 0.5, 1 );
				const spotLight2 = new THREE.SpotLight( 0xffffff, 0.3 );
				spotLight2.position.set( -0.75, 0.2, 0 );
				const spotLight3 = new THREE.SpotLight( 0xffffff, 0.3 );
				spotLight3.position.set( -0.5, 0, 1 );
				const spotLight4 = new THREE.SpotLight( 0xffffff, 0.3 );
				spotLight4.position.set( 0.5, 0.5, -1 );
				const spotLight5 = new THREE.SpotLight( 0xffffff, 0.15 );
				spotLight5.position.set( 0, -1.5, 0 );
				////spotLight.position.multiplyScalar( 700 );
				scene.add( spotLight );
				scene.add( spotLight2 );
				//div_to_scene[div_id]["geo"].add( spotLight3 );
				scene.add( spotLight4 );
				scene.add( spotLight5 );
        }

        function create_style_render_div(camera, div_id, mesh_path) {
            let container;
            let renderer, controls;

            init();
            animate();

            function init() {

                container = document.getElementById(div_id);
                let width = container.parentElement.clientWidth;
                let height = container.parentElement.clientHeight;


                div_to_render_scene[div_id]["0"] = new THREE.Scene();
                div_to_render_scene[div_id]["1"] = new THREE.Scene();
                div_to_render_scene[div_id]["2"] = new THREE.Scene();
                div_to_render_scene[div_id]["3"] = new THREE.Scene();
                div_to_render_scene[div_id]["4"] = new THREE.Scene();
                div_to_render_scene[div_id]["5"] = new THREE.Scene();
                div_to_render_scene[div_id]["6"] = new THREE.Scene();
                div_to_render_scene[div_id]["0"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["1"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["2"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["3"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["4"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["5"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["6"].background = new THREE.Color( 0xffffff );

                // PLY file

                const loader = new PLYLoader();
                ["0","2", "3", "4", "5"].forEach(id => {
                    loader.load( mesh_path + id + ".ply", function ( geometry ) {
                        geometry.computeVertexNormals();
                        //let material = new THREE.MeshStandardMaterial( { color: 0xffffff} );
                        const material = new THREE.MeshPhongMaterial( {
                                                color: 0xCCE6FF,
                                                specular: 0x222222,
                                                shininess: 25,} );
                        const mesh_color = new THREE.Mesh( geometry, material );
                        div_to_render_scene[div_id][id].add( mesh_color );
                        //if (id === "0") {
                        //let material_geo = new THREE.MeshStandardMaterial( { color: 0x444444, flatShading: true } )
                        //const mesh_geo = new THREE.Mesh( geometry, material_geo );
                        //div_to_render_scene[div_id]["geo"].add( mesh_geo );
                        //}
                        //div_to_render_scene[div_id][id].add( new THREE.HemisphereLight( 0x333333, 0x222222 ) );
                        //addShadowedLight(div_to_render_scene[div_id][id], 1, 1, 1, 0xffffff, 1.35 );
                        //addShadowedLight(div_to_render_scene[div_id][id],  0.5, 1, - 1, 0xffffff, 1 );
                        add_lights(div_to_render_scene[div_id][id]);
                    }, (xhr) => {
                        console.log((xhr.loaded / xhr.total) * 100 + '% loaded')
                    }, (error) => {
                        console.log(error)
                    }
                    );
                })



                // renderer

                renderer = new THREE.WebGLRenderer( { antialias: true } );
                renderer.setPixelRatio( window.devicePixelRatio );
                renderer.setSize( width, height);
                renderer.outputEncoding = THREE.sRGBEncoding;

                renderer.shadowMap.enabled = true;

                container.appendChild( renderer.domElement );

                controls = new OrbitControls(camera, renderer.domElement)
                controls.enableDamping = false

                // resize

                window.addEventListener( 'resize', onWindowResize );

        }
            function onWindowResize() {
                let width = container.clientWidth;
                let height = container.clientHeight;
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize( width, height );
            }
            function animate() {
                requestAnimationFrame( animate );
                render();
            }

            function render() {
                let scene = div_to_render_scene[div_id][style_id]
                renderer.render( scene, camera );
                controls.update();
            }

            return controls;
        }

        function addShadowedLight(scene, x, y, z, color, intensity ) {

            const directionalLight = new THREE.DirectionalLight( color, intensity );
            directionalLight.position.set( x, y, z );
            scene.add( directionalLight );

            directionalLight.castShadow = true;

            const d = 1;
            directionalLight.shadow.camera.left = - d;
            directionalLight.shadow.camera.right = d;
            directionalLight.shadow.camera.top = d;
            directionalLight.shadow.camera.bottom = - d;

            directionalLight.shadow.camera.near = 1;
            directionalLight.shadow.camera.far = 4;

            directionalLight.shadow.mapSize.width = 1024;
            directionalLight.shadow.mapSize.height = 1024;

            directionalLight.shadow.bias = - 0.001;

        }

        document.addEventListener('keydown', logKey);

        function logKey(evt) {
            if (evt.keyCode === 71 && !mouse_button_down) {
                switch_geometry()
            }
            if (evt.keyCode === 82 && !mouse_button_down) {
                reset_orbit_controls()
            }
        }

        function switch_geometry() {
            render_colors = !render_colors
        }

        function reset_orbit_controls() {
            list_of_orbit_controls.forEach(oc => {
                oc.reset()
                oc.autoRotate = false
            })
        }

        function set_style_0(){
            style_id = "0"
        }

        function set_style_1(){
            style_id = "1"
        }

        function set_style_2(){
            style_id = "2"
        }

        function set_style_3(){
            style_id = "3"
        }

        function set_style_4(){
            style_id = "4"
        }
        function set_style_5(){
            style_id = "5"
        }
        function set_style_6(){
            style_id = "6"
        }

        document.body.onmousedown = function(evt) {
            if (evt.button === 0)
                mouse_button_down = true
        }
        document.body.onmouseup = function(evt) {
            if (evt.button === 0)
                mouse_button_down = false
        }

        window.onload = function() {
            let slider = document.getElementsByClassName("slider")[0]
            slider.removeAttribute("tabIndex")
            // slider.addEventListener("mouseout", reset_orbit_controls);
            setup_render_divs("mesh_chair_1", './models/mesh_0049.ply')
            setup_render_divs("mesh_chair_2", './models/mesh_0063.ply')
            setup_render_divs("mesh_chair_3", './models/mesh_0079.ply')
            setup_render_divs("mesh_car_1", './models/mesh_0112.ply')
            setup_render_divs("mesh_car_3", './models/mesh_0238.ply')
            //setup_style_render_divs("mesh_style_0", './models/chair_style_0')
            //setup_style_render_divs("mesh_style_1", './models/chair_style_1')
            //setup_style_render_divs("mesh_style_2", './models/chair_style_2')
            //setup_style_render_divs("mesh_style_3", './models/chair_style_3')
            setup_style_render_divs("mesh_style_0", './models/mesh_mustafa_')
            setup_style_render_divs("mesh_style_1", './models/mesh_id98_')
            setup_style_render_divs("mesh_style_2", './models/mesh_id97_')
            setup_style_render_divs("mesh_style_3", './models/mesh_id95_')
        };

    </script>
</body>

</html>
